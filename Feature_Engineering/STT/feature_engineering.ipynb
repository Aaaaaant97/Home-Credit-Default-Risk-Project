{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa848ec-d93c-405b-bfd7-a1f4ce85bb67",
   "metadata": {},
   "source": [
    "The Feature Engineering of application_train/test.csv\n",
    "\n",
    "(1)feature_engineering_v0（baseline）: including missing_dealing、anomalies_dealing、 and onehot_encode\n",
    "\n",
    "(2)feature_engineering_v1: baseline + label_encode\n",
    "\n",
    "(3)feature_engineering_v2: baseline + domain_feature\n",
    "\n",
    "(4)feature_engineering_v3: baseline + age_feature\n",
    "\n",
    "(5)feature_engineering_v4: baseline + region_feature\n",
    "\n",
    "(6)feature_engineering_v5: baseline + EXT_SOURCE_feature\n",
    "\n",
    "(7)feature_engineering_v6: baseline + document_phone_feature\n",
    "\n",
    "(8)feature_engineering_v7: ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353bba8-1fb3-43e5-b01a-da6c98c590fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def deal_anomalies(app_train, app_test):\n",
    "    # Create an anomalous flag column\n",
    "    app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "    app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "    app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "    app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "    num_cols_common = [c for c in app_train.columns if c in app_test.columns and pd.api.types.is_numeric_dtype(app_train[c])]\n",
    "    miss_rates = app_train[num_cols_common].isna().mean().sort_values(ascending=False)\n",
    "\n",
    "    selected_miss_cols = [c for c in miss_rates.index if miss_rates[c] >= 0.5]\n",
    "    for c in selected_miss_cols:\n",
    "        app_train[f\"MISS__{c}\"] = app_train[c].isna().astype('int8')\n",
    "        app_test[f\"MISS__{c}\"]  = app_test[c].isna().astype('int8')\n",
    "\n",
    "    app_train['ROW_MISSING_RATIO'] = app_train.isna().mean(axis=1)\n",
    "    app_test['ROW_MISSING_RATIO']  = app_test.isna().mean(axis=1)\n",
    "    return app_train, app_test\n",
    "\n",
    "def onehot_encoder(app_train, app_test):\n",
    "    app_train = pd.get_dummies(app_train)\n",
    "    app_test = pd.get_dummies(app_test)\n",
    "    train_labels = app_train['TARGET']\n",
    "\n",
    "    # Align the training and testing data, keep only columns present in both dataframes\n",
    "    app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "    # Add the target back in\n",
    "    app_train['TARGET'] = train_labels\n",
    "    return app_train, app_test\n",
    "\n",
    "\n",
    "def label_encoder_1(app_train, app_test):\n",
    "    # List for storing categorical indices\n",
    "    features = app_train.copy()\n",
    "    test_features = app_test.copy()\n",
    "    # train_sk_id = app_train['SK_ID_CURR']\n",
    "    # train_target = app_train['TARGET']\n",
    "    # test_sk_id = app_test['SK_ID_CURR']\n",
    "    # features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    # test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    object_list = ['NAME_EDUCATION_TYPE','NAME_HOUSING_TYPE','NAME_INCOME_TYPE','NAME_TYPE_SUITE']\n",
    "    cat_indices = []\n",
    "    for obj in object_list:\n",
    "        obj_dict = {}\n",
    "\n",
    "        train_obj_mode = features[obj].mode()[0]\n",
    "        features[obj] = features[obj].fillna(train_obj_mode)\n",
    "        test_obj_mode = features[obj].mode()[0]\n",
    "        test_features[obj] = test_features[obj].fillna(test_obj_mode)\n",
    "\n",
    "        train_cat_perc = features[[obj, 'TARGET']].groupby([obj],as_index=False).mean()\n",
    "        train_cat_perc.sort_values(by='TARGET', ascending=True, inplace=True)\n",
    "        for index, x in enumerate(train_cat_perc.values):\n",
    "            obj_dict[x[0]] = index\n",
    "        features[obj] = features[obj].map(obj_dict)\n",
    "        test_features[obj] = test_features[obj].map(obj_dict)\n",
    "        cat_indices.append(features.columns.get_loc(obj) - 2)\n",
    "\n",
    "    return features, test_features, cat_indices\n",
    "\n",
    "def domain_feature(app_train, app_test):\n",
    "    # The multiple of the trust amount relative to the annual income,\n",
    "    # Intuition: The higher the leverage, the higher the default risk is usually\n",
    "    app_train['CREDIT_TO_INCOME'] = app_train['AMT_CREDIT'] / app_train['AMT_INCOME_TOTAL']\n",
    "    app_test['CREDIT_TO_INCOME']  = app_test['AMT_CREDIT'] / app_test['AMT_INCOME_TOTAL']\n",
    "\n",
    "    # Annuity (installment annualization) as a percentage of annual income. \n",
    "    # Intuition: The higher the proportion, the heavier the burden and the greater the cash flow pressure.\n",
    "    app_train['ANNUITY_TO_INCOME'] = app_train['AMT_ANNUITY'] / app_train['AMT_INCOME_TOTAL']\n",
    "    app_test['ANNUITY_TO_INCOME']  = app_test['AMT_ANNUITY'] / app_test['AMT_INCOME_TOTAL']\n",
    "\n",
    "    # Monthly repayment burden rate. \n",
    "    # Intuition: The commonly used debt to income ratio (DTI) approximation term indicates that the higher the risk, the higher the risk.\n",
    "    # app_train['PAYMENT_BURDEN_MONTHLY'] = app_train['AMT_ANNUITY'] / (app_train['AMT_INCOME_TOTAL'] / 12.0)\n",
    "    # app_test['PAYMENT_BURDEN_MONTHLY']  = app_test['AMT_ANNUITY'] / (app_test['AMT_INCOME_TOTAL'] / 12.0)\n",
    "\n",
    "    # The relative annual income of commodity prices. \n",
    "    # Intuition: The higher the large consumption relative to income, the higher the possibility of default.\n",
    "    app_train['GOODS_TO_INCOME'] = app_train['AMT_GOODS_PRICE'] / app_train['AMT_INCOME_TOTAL']\n",
    "    app_test['GOODS_TO_INCOME']  = app_test['AMT_GOODS_PRICE']  / app_test['AMT_INCOME_TOTAL']\n",
    "\n",
    "    # The annuity intensity of each unit's credit is a comprehensive reflection of interest rate/term; \n",
    "    # Intuition: Higher may mean higher interest rates or shorter terms\n",
    "    app_train['ANNUITY_TO_CREDIT'] = app_train['AMT_ANNUITY'] / app_train['AMT_CREDIT']\n",
    "    app_test['ANNUITY_TO_CREDIT']  = app_test['AMT_ANNUITY']  / app_test['AMT_CREDIT']\n",
    "\n",
    "    # Estimate the loan term (in months), the longer the term\n",
    "    # Intuition: the lower the monthly payment but the longer the total risk exposure period; The relationship with risk is not monotonous.\n",
    "    app_train['TERM_MONTHS_EST'] = (app_train['AMT_CREDIT'] / app_train['AMT_ANNUITY']).clip(1, 1200)\n",
    "    app_test['TERM_MONTHS_EST']  = (app_test['AMT_CREDIT']  / app_test['AMT_ANNUITY']).clip(1, 1200)\n",
    "\n",
    "    # The credit amount is relative to the commodity price. \n",
    "    # Intuition: >1 may include interest/surcharges/bundled amount; Too high may pose greater risks\n",
    "    app_train['CREDIT_TO_GOODS'] = app_train['AMT_CREDIT'] / app_train['AMT_GOODS_PRICE']\n",
    "    app_test['CREDIT_TO_GOODS']  = app_test['AMT_CREDIT']  / app_test['AMT_GOODS_PRICE']\n",
    "\n",
    "    # Per capita income, \n",
    "    # Intuition: the lighter the burden of support, the stronger the ability to pay.\n",
    "    app_train['INCOME_PER_PERSON'] = app_train['AMT_INCOME_TOTAL'] / app_train['CNT_FAM_MEMBERS'].replace(0, np.nan)\n",
    "    app_test['INCOME_PER_PERSON']  = app_test['AMT_INCOME_TOTAL']  / app_test['CNT_FAM_MEMBERS'].replace(0, np.nan)\n",
    "\n",
    "    return app_train, app_test\n",
    "\n",
    "def age_employment_feature(app_train, app_test):\n",
    "    # Age/seniority/stability interaction\n",
    "    #The proportion of years of service to age. Longitudinal characterization of career stability; Too low a proportion may result in insufficient job stability\n",
    "    app_train['EMPLOY_TO_AGE'] = app_train['DAYS_EMPLOYED'] / app_train['DAYS_BIRTH']\n",
    "    app_test['EMPLOY_TO_AGE']  = app_test['DAYS_EMPLOYED']  / app_test['DAYS_BIRTH']\n",
    "\n",
    "\n",
    "    # Standardization of vehicle age relative to age, proxy for purchasing power or asset stability\n",
    "    app_train['OWN_CAR_AGE_NORM'] = -app_train['OWN_CAR_AGE'] / (app_train['DAYS_BIRTH'] / 365.0)\n",
    "    app_test['OWN_CAR_AGE_NORM']  = -app_test['OWN_CAR_AGE']  / (app_test['DAYS_BIRTH'] / 365.0)\n",
    "\n",
    "    # Number of children corresponding to age every 10 years. \n",
    "    # The coupling of family burden and life stages; Indirect impact on disposable income and default\n",
    "    app_train['CHILDREN_PER_10Y'] = -app_train['CNT_CHILDREN'] / ((app_train['DAYS_BIRTH'] / 10.0) / 365.0)\n",
    "    app_test['CHILDREN_PER_10Y']  = -app_test['CNT_CHILDREN']  / ((app_test['DAYS_BIRTH'] / 10.0) / 365.0)\n",
    "    return app_train, app_test\n",
    "\n",
    "def region_score_feature(app_train, app_test):\n",
    "    # Regional rating/address consistency\n",
    "    app_train['REGION_RATING_DIFF'] = app_train['REGION_RATING_CLIENT'] - app_train['REGION_RATING_CLIENT_W_CITY']\n",
    "    app_test['REGION_RATING_DIFF']  = app_test['REGION_RATING_CLIENT']  - app_test['REGION_RATING_CLIENT_W_CITY']\n",
    "\n",
    "    addr_cols = [\n",
    "        'REG_REGION_NOT_LIVE_REGION','REG_REGION_NOT_WORK_REGION','LIVE_REGION_NOT_WORK_REGION',\n",
    "        'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY','LIVE_CITY_NOT_WORK_CITY'\n",
    "    ]\n",
    "    present_train = [c for c in addr_cols if c in app_train.columns]\n",
    "    present_test  = [c for c in addr_cols if c in app_test.columns]\n",
    "    present = [c for c in addr_cols if c in present_train and c in present_test]\n",
    "\n",
    "    app_train['ADDR_MISMATCH_SUM'] = app_train[present].sum(axis=1)\n",
    "    app_test['ADDR_MISMATCH_SUM']  = app_test[present].sum(axis=1)\n",
    "    return app_train, app_test\n",
    "\n",
    "def EXT_SOURCE_feature(app_train, app_test):\n",
    "    # External data EXT_SOURCE statistics\n",
    "    ext_cols = [c for c in ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3'] if c in app_train.columns and c in app_test.columns]\n",
    "\n",
    "    app_train['EXT_MEAN'] = app_train[ext_cols].mean(axis=1)\n",
    "    app_test['EXT_MEAN']  = app_test[ext_cols].mean(axis=1)\n",
    "\n",
    "    app_train['EXT_STD'] = app_train[ext_cols].std(axis=1)\n",
    "    app_test['EXT_STD']  = app_test[ext_cols].std(axis=1)\n",
    "\n",
    "    app_train['EXT_MIN'] = app_train[ext_cols].min(axis=1)\n",
    "    app_test['EXT_MIN']  = app_test[ext_cols].min(axis=1)\n",
    "\n",
    "    app_train['EXT_MAX'] = app_train[ext_cols].max(axis=1)\n",
    "    app_test['EXT_MAX']  = app_test[ext_cols].max(axis=1)\n",
    "\n",
    "    app_train['EXT_MEAN_X_AGE'] = app_train['EXT_MEAN'] *  (-app_train['DAYS_BIRTH'] / 365.0)\n",
    "    app_test['EXT_MEAN_X_AGE']  = app_test['EXT_MEAN']  *  (-app_train['DAYS_BIRTH'] / 365.0)\n",
    "\n",
    "    app_train['EXT_MEAN_X_LOG_INCOME'] = app_train['EXT_MEAN'] * np.log1p(app_train['AMT_INCOME_TOTAL'])\n",
    "    app_test['EXT_MEAN_X_LOG_INCOME']  = app_test['EXT_MEAN']  * np.log1p(app_test['AMT_INCOME_TOTAL'])\n",
    "\n",
    "    app_train['EXT_MISSING_CNT'] = app_train[ext_cols].isna().sum(axis=1)\n",
    "    app_test['EXT_MISSING_CNT']  = app_test[ext_cols].isna().sum(axis=1)\n",
    "\n",
    "    return app_train, app_test\n",
    "\n",
    "def document_phone_feature(app_train, app_test):\n",
    "    # Documents and contact information\n",
    "    doc_cols = [c for c in app_train.columns if c.startswith('FLAG_DOCUMENT_') and c in app_test.columns]\n",
    "    app_train['DOCS_SUBMITTED_CNT'] = app_train[doc_cols].sum(axis=1)\n",
    "    app_test['DOCS_SUBMITTED_CNT']  = app_test[doc_cols].sum(axis=1)\n",
    "\n",
    "    app_train['DOCS_ANY'] = (app_train['DOCS_SUBMITTED_CNT'] > 0).astype('int8')\n",
    "    app_test['DOCS_ANY']  = (app_test['DOCS_SUBMITTED_CNT']  > 0).astype('int8')\n",
    "\n",
    "    phone_cols = [c for c in ['FLAG_MOBIL','FLAG_EMP_PHONE','FLAG_WORK_PHONE','FLAG_CONT_MOBILE','FLAG_PHONE','FLAG_EMAIL'] if c in app_train.columns and c in app_test.columns]\n",
    "    app_train['CONTACT_FLAGS_SUM'] = app_train[phone_cols].sum(axis=1)\n",
    "    app_test['CONTACT_FLAGS_SUM']  = app_test[phone_cols].sum(axis=1)\n",
    "\n",
    "    return app_train, app_test\n",
    "\n",
    "\n",
    "def feature_engineering_v0(app_train, app_test):\n",
    "    # missing anomalies and onehot\n",
    "    app_train, app_test = deal_anomalies(app_train, app_test)\n",
    "    app_train, app_test = onehot_encoder(app_train, app_test)\n",
    "    cat_indices = []\n",
    "    return app_train, app_test, cat_indices\n",
    "\n",
    "def feature_engineering_v1(app_train, app_test):\n",
    "    # missing anomalies labelcode and onehot\n",
    "    app_train, app_test = deal_anomalies(app_train, app_test)\n",
    "    app_train, app_test, cat_indices = label_encoder_1(app_train, app_test)\n",
    "    app_train, app_test = onehot_encoder(app_train, app_test)\n",
    "    return app_train, app_test, cat_indices\n",
    "\n",
    "\n",
    "def feature_engineering_v2(app_train, app_test):\n",
    "    # missing anomalies domain and onehot\n",
    "    app_train, app_test = deal_anomalies(app_train, app_test)\n",
    "    app_train, app_test = domain_feature(app_train, app_test)\n",
    "    app_train, app_test = onehot_encoder(app_train, app_test)\n",
    "    cat_indices = []\n",
    "    return app_train, app_test, cat_indices\n",
    "\n",
    "\n",
    "def feature_engineering_v3(app_train, app_test):\n",
    "    # missing anomalies age and onehot\n",
    "    app_train, app_test = deal_anomalies(app_train, app_test)\n",
    "    app_train, app_test = age_employment_feature(app_train, app_test)\n",
    "    app_train, app_test = onehot_encoder(app_train, app_test)\n",
    "    cat_indices = []\n",
    "    return app_train, app_test, cat_indices\n",
    "\n",
    "def feature_engineering_v4(app_train, app_test):\n",
    "    # missing anomalies region and onehot\n",
    "    app_train, app_test = deal_anomalies(app_train, app_test)\n",
    "    app_train, app_test = region_score_feature(app_train, app_test)\n",
    "    app_train, app_test = onehot_encoder(app_train, app_test)\n",
    "    cat_indices = []\n",
    "    return app_train, app_test, cat_indices\n",
    "\n",
    "def feature_engineering_v5(app_train, app_test):\n",
    "    # missing anomalies EXT_SOURCE_feature and onehot\n",
    "    app_train, app_test = deal_anomalies(app_train, app_test)\n",
    "    app_train, app_test = EXT_SOURCE_feature(app_train, app_test)\n",
    "    app_train, app_test = onehot_encoder(app_train, app_test)\n",
    "    cat_indices = []\n",
    "    return app_train, app_test, cat_indices\n",
    "\n",
    "def feature_engineering_v6(app_train, app_test):\n",
    "    # missing anomalies document_phone_feature and onehot\n",
    "    app_train, app_test = deal_anomalies(app_train, app_test)\n",
    "    app_train, app_test = document_phone_feature(app_train, app_test)\n",
    "    app_train, app_test = onehot_encoder(app_train, app_test)\n",
    "    cat_indices = []\n",
    "    return app_train, app_test, cat_indices\n",
    "\n",
    "\n",
    "def feature_engineering_v7(app_train, app_test):\n",
    "    # all feature\n",
    "    # V0\n",
    "    app_train, app_test = deal_anomalies(app_train, app_test)\n",
    "    # V1\n",
    "    app_train, app_test, cat_indices = label_encoder_1(app_train, app_test)\n",
    "    # V2\n",
    "    app_train, app_test = domain_feature(app_train, app_test)\n",
    "    # V3\n",
    "    app_train, app_test = age_employment_feature(app_train, app_test)\n",
    "    # V5\n",
    "    app_train, app_test = EXT_SOURCE_feature(app_train, app_test)\n",
    "    # V6\n",
    "    app_train, app_test = document_phone_feature(app_train, app_test)\n",
    "\n",
    "    app_train, app_test = onehot_encoder(app_train, app_test)\n",
    "    cat_indices = []\n",
    "    return app_train, app_test, cat_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
